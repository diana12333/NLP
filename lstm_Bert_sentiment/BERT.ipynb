{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2BGK1XLEf8r"
   },
   "source": [
    "# Transformers and BERT\n",
    "learn how to apply pre-trained BERT model to improve text classification. Bidirectional Encoder Representations from Transformers (BERT) is a technique for NLP (Natural Language Processing) pre-training developed by Google. BERT was created and published in 2018 by Jacob Devlin and his colleagues from Google. Google is leveraging BERT to better understand user searches. (From WIKI)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Read more: http://jalammar.github.io/illustrated-transformer/\n",
    "\n",
    "BERT paper: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
    "\n",
    "Understanding BERT: https://towardsdatascience.com/understanding-bert-is-it-a-game-changer-in-nlp-7cca943cf3ad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GhsCy3dQEpmu"
   },
   "source": [
    "## Preparing Dataset\n",
    "Set random seed\n",
    "\n",
    "Make sure that you are using Python3 and a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7keSeDS2EZyV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "SEED = 1001\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTwlt9C8ughd"
   },
   "source": [
    "We use an existing library called `transformers` to import BERT models.  Now let's install it first. \n",
    "\n",
    "Read more in the repo: https://github.com/huggingface/transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "3cf_NmmMEzUR",
    "outputId": "7885093a-6699-45e0-e154-cc9828b372f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
      "\r",
      "\u001b[K     |▋                               | 10kB 22.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 20kB 31.8MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 30kB 37.6MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 40kB 42.6MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 51kB 47.1MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 61kB 51.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 71kB 45.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 81kB 46.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 92kB 49.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 102kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 112kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 122kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 133kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 143kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 153kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 163kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 174kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 184kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 194kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 204kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 215kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 225kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 235kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 245kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 256kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 266kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 276kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 286kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 296kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 307kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 317kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 327kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 337kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 348kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 358kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 368kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 378kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 389kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 399kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 409kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 419kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 430kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 440kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 450kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 460kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 471kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 481kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 491kB 46.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 501kB 46.3MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 67.3MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 53.9MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 60.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=8229877379339b7c3e3d0d70aee132aca487b2f49193d01236500ffae7c278cd\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
     ]
    }
   ],
   "source": [
    "# make sure that transformers library is installed\n",
    "! pip install transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YXTHansbvA4A"
   },
   "source": [
    "We now import the tokenizer, this is to tokenize sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146,
     "referenced_widgets": [
      "28f46bb8b6704b5e8c8b23775d729a22",
      "60f6d057afdb4998a755789f0f29b0c1",
      "f1f51751d18c4984aae9aee51f0e7971",
      "f6fc95f39c72412b97e62023f1dab310",
      "bcd67acc3c534a358eb9a1e62a889337",
      "e4ae8e8234244089b0172b1901288a5e",
      "9460143f748e4b93882bcd0131927466",
      "d9acf84a1a874f7ca580b6504f2642dc"
     ]
    },
    "colab_type": "code",
    "id": "JueLVzpHEvOA",
    "outputId": "41565765-2763-4824-dff6-fee3d21d9643"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f46bb8b6704b5e8c8b23775d729a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "512\n",
      "['hello', 'world', 'how', 'are', 'you', '?']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "#  use a pre-trained version ('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "\n",
    "print(max_input_length)\n",
    "\n",
    "len(tokenizer.vocab)\n",
    "\n",
    "# tokenize a sentence\n",
    "tokens = tokenizer.tokenize('Hello WORLD how ARE yoU?')\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "# There will be a warning, but just leave it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jX9jWiW9vQC2"
   },
   "source": [
    "Now we convert the tokens into IDs.\n",
    "\n",
    "And we list the IDs, and some spcial tokens: `<CLS>` means classification token; `<SEP>` means a separator between two sentences, and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9HBjW5VAE9nn",
    "outputId": "adbfff1e-7117-443c-8d6b-9d9aea6f4a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7592, 2088, 2129, 2024, 2017, 1029]\n",
      "[CLS] [SEP] [PAD] [UNK]\n",
      "101 102 0 100\n"
     ]
    }
   ],
   "source": [
    "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(indexes)\n",
    "\n",
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)\n",
    "\n",
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJbMuqdmFNOb"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJCwGREyvx0c"
   },
   "source": [
    "Prepare TEXT and LABEL ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2FwmclZFQH2"
   },
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "\n",
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "tfiCUKTOVKUC",
    "outputId": "a060c939-ea47-4386-ba7c-a0c01c6d1462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    " \n",
    " from google.colab import drive\n",
    " drive.mount('/content/gdrive')\n",
    " # set up the path\n",
    "ROOT_DIR = \" gdrive/My\\ Drive/Colab\\ Notebooks/nlp_hw2/\"\n",
    "DATA_DIR = ROOT_DIR+'IMDB.gz'\n",
    "\n",
    "#4/xAFYd3Unt680_SJ44Q9KNnHA68xurTaXUaR4EG846l0a9QHnpXZdnXg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ler852YiFSO3",
    "outputId": "ca336918-5ae2-4681-c045-7ffb520509f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of validation examples: 7500\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "##  use the IMDB data, and split into training and testing \n",
    "from torchtext import datasets\n",
    "\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT,LABEL)\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n",
    "#train_data, valid_data = datasets.IMDB.splits(TEXT,LABEL)\n",
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "VOE8PJcQF9-r",
    "outputId": "3c1078ce-a266-42bf-f539-ecc2788728ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', 'the', 'house', 'that', 'dripped', 'blood', '\"', 'is', 'one', 'of', 'the', 'better', 'anthology', 'films', 'of', 'the', 'time', 'period', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', '*', '*', 'spoil', '##ers', '*', '*', '<', 'br', '/', '>', '<', 'br', '/', '>', 'tracking', 'down', 'a', 'missing', 'film', 'star', ',', 'inspector', 'holloway', ',', '(', 'john', 'bennett', ')', 'finds', 'that', 'the', 'last', 'reported', 'sighting', 'was', 'in', 'a', 'large', 'mansion', 'in', 'the', 'countryside', '.', 'during', 'the', 'course', 'of', 'looking', 'through', 'the', 'house', ',', 'he', 'is', 'told', 'four', 'different', 'stories', 'about', 'past', 'residents', 'of', 'the', 'house', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'good', 'story', '(', 's', ')', ':', 'method', 'for', 'murder', '-', 'moving', 'into', 'the', 'mysterious', 'manor', 'to', 'get', 'some', 'peace', 'and', 'quiet', 'while', 'charles', 'pens', 'his', 'latest', 'master', '##work', ',', 'horror', 'novelist', 'charles', 'hilly', '##er', ',', '(', 'den', '##holm', 'elliott', ')', 'and', 'his', 'wife', 'alice', ',', '(', 'joanna', 'dun', '##ham', ')', 'are', 'thrilled', 'with', 'the', 'story', ',', 'which', 'centers', 'around', 'a', 'serial', 'st', '##rangle', '##r', 'named', 'dominic', '.', 'after', 'a', 'series', 'of', 'strange', 'accidents', 'and', 'experiences', 'in', 'the', 'house', ',', 'charles', 'begins', 'to', 'believe', 'that', 'the', 'creation', 'my', 'have', 'come', 'to', 'life', 'and', 'is', 'haunting', 'him', 'and', 'his', 'wife', '.', 'probably', 'one', 'of', 'the', 'better', 'entries', 'in', 'the', 'film', ',', 'it', \"'\", 's', 'easily', 'the', 'creep', '##iest', '.', 'the', 'atmosphere', 'here', 'is', 'what', 'sets', 'it', 'apart', '.', 'the', 'scenes', 'with', 'the', 'fictional', 'character', 'are', 'genuinely', 'creepy', ',', 'the', 'mystery', 'surrounding', 'him', 'is', 'really', 'effective', 'and', 'there', \"'\", 's', 'always', 'a', 'classic', 'creep', '-', 'out', 'moment', '.', 'the', 'classic', 'moment', 'is', 'the', 'kill', 'in', 'the', 'psychiatrist', \"'\", 's', 'office', ',', 'which', 'is', 'an', 'all', '-', 'time', 'high', 'for', 'creep', '##iness', '.', 'the', 'build', '-', 'up', 'to', 'it', ',', 'with', 'the', 'cr', '##eak', '##ing', 'sounds', ',', 'quick', 'flashes', 'of', 'a', 'mysterious', 'being', ',', 'and', 'the', 'thunder', 'and', 'lightning', 'in', 'the', 'back', 'ground', 'work', 'well', 'for', 'this', 'one', \"'\", 's', 'favor', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'sweets', 'for', 'the', 'sweet', '-', 'moving', 'into', 'a', 'new', 'house', ',', 'widow', '##er', 'john', 'reid', ',', '(', 'christopher', 'lee', ')', 'hires', 'former', 'school', 'teacher', 'ann', 'norton', ',', '(', 'ny', '##ree', 'dawn', 'porter', ')', 'for', 'his', 'young', 'daughter', 'jane', ',', '(', 'chloe', 'franks', ')', 'while', 'he', \"'\", 's', 'away', 'on', 'business', '.', 'ann', 'gradually', 'begins', 'to', 'un', '##rave', '##l', 'a', 'dark', 'secret', 'from', 'jane', \"'\", 's', 'past', ',', 'which', 'john', 've', '##hem', '##ently', 'denies', '.', 'when', 'she', 'learns', 'the', 'true', 'nature', 'of', 'what', 'has', 'happened', ',', 'it', \"'\", 's', 'far', 'more', 'shocking', 'that', 'what', 'she', 'could', \"'\", 've', 'thought', 'possible', '.', 'with', 'the', 'creep', '##iest', 'outright', 'plot', 'and', 'the', 'biggest', 'twist', 'of', 'the', 'stories', ',', 'this', 'is', 'a', 'quite', 'pleasant', 'entry', '.', 'the', 'mystery', 'of', 'the', 'family', 'is', 'wonderful', '##ly', 'played', 'out', ',', 'with', 'small', 'amounts', 'of', 'clues', 'piled', 'up', 'here', 'and', 'there', ',', 'and', 'the', 'final', 'revelation', 'is', 'down', '##right', 'nerve', '-', 'wr', '##ack', '##ing', '.', 'that', 'part', 'alone', 'is', 'the', 'main', 'reason', 'why', 'this', 'one', 'works', ',', 'and', 'lee', 'doesn', \"'\", 't', 'harm', 'it', 'either', '.', '<', 'br', '/', '>', '<', 'br']\n",
      "{'text': [1000, 1996, 2160, 2008, 22526, 2668, 1000, 2003, 2028, 1997, 1996, 2488, 9637, 3152, 1997, 1996, 2051, 2558, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1008, 1008, 27594, 2545, 1008, 1008, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 9651, 2091, 1037, 4394, 2143, 2732, 1010, 7742, 20977, 1010, 1006, 2198, 8076, 1007, 4858, 2008, 1996, 2197, 2988, 29426, 2001, 1999, 1037, 2312, 7330, 1999, 1996, 10833, 1012, 2076, 1996, 2607, 1997, 2559, 2083, 1996, 2160, 1010, 2002, 2003, 2409, 2176, 2367, 3441, 2055, 2627, 3901, 1997, 1996, 2160, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 2204, 2466, 1006, 1055, 1007, 1024, 4118, 2005, 4028, 1011, 3048, 2046, 1996, 8075, 6952, 2000, 2131, 2070, 3521, 1998, 4251, 2096, 2798, 25636, 2010, 6745, 3040, 6198, 1010, 5469, 9974, 2798, 22800, 2121, 1010, 1006, 7939, 18884, 9899, 1007, 1998, 2010, 2564, 5650, 1010, 1006, 15730, 24654, 3511, 1007, 2024, 16082, 2007, 1996, 2466, 1010, 2029, 6401, 2105, 1037, 7642, 2358, 21476, 2099, 2315, 11282, 1012, 2044, 1037, 2186, 1997, 4326, 13436, 1998, 6322, 1999, 1996, 2160, 1010, 2798, 4269, 2000, 2903, 2008, 1996, 4325, 2026, 2031, 2272, 2000, 2166, 1998, 2003, 20161, 2032, 1998, 2010, 2564, 1012, 2763, 2028, 1997, 1996, 2488, 10445, 1999, 1996, 2143, 1010, 2009, 1005, 1055, 4089, 1996, 19815, 10458, 1012, 1996, 7224, 2182, 2003, 2054, 4520, 2009, 4237, 1012, 1996, 5019, 2007, 1996, 7214, 2839, 2024, 15958, 17109, 1010, 1996, 6547, 4193, 2032, 2003, 2428, 4621, 1998, 2045, 1005, 1055, 2467, 1037, 4438, 19815, 1011, 2041, 2617, 1012, 1996, 4438, 2617, 2003, 1996, 3102, 1999, 1996, 18146, 1005, 1055, 2436, 1010, 2029, 2003, 2019, 2035, 1011, 2051, 2152, 2005, 19815, 9961, 1012, 1996, 3857, 1011, 2039, 2000, 2009, 1010, 2007, 1996, 13675, 25508, 2075, 4165, 1010, 4248, 16121, 1997, 1037, 8075, 2108, 1010, 1998, 1996, 8505, 1998, 7407, 1999, 1996, 2067, 2598, 2147, 2092, 2005, 2023, 2028, 1005, 1055, 5684, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 26844, 2005, 1996, 4086, 1011, 3048, 2046, 1037, 2047, 2160, 1010, 7794, 2121, 2198, 9027, 1010, 1006, 5696, 3389, 1007, 28208, 2280, 2082, 3836, 5754, 10770, 1010, 1006, 6396, 9910, 6440, 8716, 1007, 2005, 2010, 2402, 2684, 4869, 1010, 1006, 9318, 21310, 1007, 2096, 2002, 1005, 1055, 2185, 2006, 2449, 1012, 5754, 6360, 4269, 2000, 4895, 22401, 2140, 1037, 2601, 3595, 2013, 4869, 1005, 1055, 2627, 1010, 2029, 2198, 2310, 29122, 28198, 23439, 1012, 2043, 2016, 10229, 1996, 2995, 3267, 1997, 2054, 2038, 3047, 1010, 2009, 1005, 1055, 2521, 2062, 16880, 2008, 2054, 2016, 2071, 1005, 2310, 2245, 2825, 1012, 2007, 1996, 19815, 10458, 13848, 5436, 1998, 1996, 5221, 9792, 1997, 1996, 3441, 1010, 2023, 2003, 1037, 3243, 8242, 4443, 1012, 1996, 6547, 1997, 1996, 2155, 2003, 6919, 2135, 2209, 2041, 1010, 2007, 2235, 8310, 1997, 15774, 17835, 2039, 2182, 1998, 2045, 1010, 1998, 1996, 2345, 11449, 2003, 2091, 15950, 9113, 1011, 23277, 8684, 2075, 1012, 2008, 2112, 2894, 2003, 1996, 2364, 3114, 2339, 2023, 2028, 2573, 1010, 1998, 3389, 2987, 1005, 1056, 7386, 2009, 2593, 1012, 1026, 7987, 1013, 1028, 1026, 7987], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[6])['text'])\n",
    "\n",
    "print(tokens)\n",
    "print(vars(train_data.examples[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzeWiB_8F_fA"
   },
   "outputs": [],
   "source": [
    "# build vocab\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwPwq8fNGMoe"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-IiTsTu7GQZ1"
   },
   "source": [
    "## Model building\n",
    "\n",
    "Import the `BertModel`, and we load from the pre-trained model by giving the path. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "2739ec6f25cc4fb19358a7eb5718a5fa",
      "4853c512aad14ee29db649dab221978e",
      "27b96391280d493baed65b2f024b8664",
      "352fe954bf8c4b60ac85327f1a3190ae",
      "931ea5d0c0fd40d4b28f4cb1266bf7ec",
      "cbf08395a6d44b52a6a30fd76a467f55",
      "4a310ab0da8b496e9c9b385268500a74",
      "28bd0cc7fcd248bc9172d27317dda90f",
      "b3da39ce6cd9494287b1cc0ce2b6e44a",
      "4aa6fbbac08a474d92db033d592b84b5",
      "89b37bc329d742289048bfd093cd619b",
      "c88d21196806475c9937d5474cbc06a0",
      "dd3a493815d84118952b5f86ed7b44d0",
      "8c40014b839940bc86adb70c64b4a63f",
      "5de8dafa39d34efabe7a6d6296a1dc2a",
      "37a6ecf6bf224f998bb7e326a35b7daa"
     ]
    },
    "colab_type": "code",
    "id": "oZpl05CbGSeX",
    "outputId": "17a9b012-fed6-4663-b2b2-256eddfb0f40"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2739ec6f25cc4fb19358a7eb5718a5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3da39ce6cd9494287b1cc0ce2b6e44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "# It will download the pre-trained model\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7YfnzOCAZI6T"
   },
   "source": [
    "## Applying BERT to classification\n",
    "\n",
    "It is possible to use the BERT model directly, however, the free GPU is not large enough to load the whole model; \n",
    "So let's try to use the pre-trained embedding layer. Then we train our own RNN layer on top of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHTCN8nnGYMf"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyBERTwithRNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional,\n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            embedded = self.bert(text)[0]\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        _, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #hidden = [n layers * n directions, batch size, emb dim]\n",
    "        \n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "                \n",
    "        #hidden = [batch size, hid dim]\n",
    "        \n",
    "        output = self.out(hidden)\n",
    "        \n",
    "        #output = [batch size, out dim]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BpTj_vfDGig5"
   },
   "outputs": [],
   "source": [
    "## creat model instance\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "model = MyBERTwithRNN(bert,\n",
    "                         HIDDEN_DIM,\n",
    "                         OUTPUT_DIM,\n",
    "                         N_LAYERS,\n",
    "                         BIDIRECTIONAL,\n",
    "                         DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dtD_O5xwGqVA",
    "outputId": "eb8d9bfc-453f-45bb-aeb3-785ef020b94d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 112,241,409 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    ## fill here:\n",
    "    param_number = 0\n",
    "    param_number = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    \n",
    "    return param_number\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vGHTehzQGu3C"
   },
   "outputs": [],
   "source": [
    "# Let's fix the bert embeddings\n",
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v-So8zd6HwXZ"
   },
   "source": [
    "## Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SS6DfSHN-rB"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lr_yTNfNHy4Z"
   },
   "outputs": [],
   "source": [
    "## the accuracy function (Hint: similar to the same function from PartB)\n",
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    acc = (rounded_preds == y).float() \n",
    "    acc = acc.sum() / len(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJetyYsjN2Wm"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "          \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3Rb2_kUNoaK"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "        \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKX3rfEQRwPR"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# a helper function to see how much time needed\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "T-KFFkv6Nurd",
    "outputId": "fb390805-f748-4223-e92b-49db5eb29ff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 17m 6s\n",
      "\tTrain Loss: 0.463 | Train Acc: 77.09%\n",
      "\t Val. Loss: 0.295 |  Val. Acc: 87.88%\n",
      "Epoch: 02 | Epoch Time: 17m 13s\n",
      "\tTrain Loss: 0.262 | Train Acc: 89.60%\n",
      "\t Val. Loss: 0.242 |  Val. Acc: 90.34%\n"
     ]
    }
   ],
   "source": [
    "# Start training.\n",
    "\n",
    "N_EPOCHS = 2\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EZeSgxe5OKlC",
    "outputId": "5a802a06-cdec-4e8d-fe41-8aa349217a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.225 | Test Acc: 90.89%\n"
     ]
    }
   ],
   "source": [
    "# Load the best model and evaluate; this may take about 5-10 mins; the Test Accuracy is higher than 90%\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BHRaEwbWOWrY"
   },
   "source": [
    "## Inference on your own sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZVbz-ohOd0k"
   },
   "outputs": [],
   "source": [
    "## Each sentence when converting into the index, should have [CLS] tag at the beginning and [SEP] tag in the end. \n",
    "def my_predict(model, tokenizer, sentence):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bwtE71M_Ohwe",
    "outputId": "7bd83eaf-662e-45a9-b9a4-f814989d1407"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03143218532204628"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the score should be close to 0\n",
    "my_predict(model, tokenizer, \"This film is terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0bYjd5AVOnPY",
    "outputId": "48d84360-d249-4f43-edcd-9258aa0b0dbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850237369537354"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the score should be close to 1\n",
    "my_predict(model, tokenizer, \"I like it !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IDJ_9Eh9XYq2"
   },
   "source": [
    "**Question**: how do you compare the bert model with PartB? (Hint: training time, accuracy, etc.) Please answer in the next Text cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qD9S-636Xpbc"
   },
   "source": [
    "**Answer**: \n",
    "1. Training time takes longer time to train 17 mins an epoch versus 30 seconds an epoch.\n",
    "2. Accuracy: has a much higher accuracy 90%  vs 50%/70%\n",
    "3. Much more parameters:112,241,409 compared to part B. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgPH1Z_9wWID"
   },
   "source": [
    "## Submission\n",
    "\n",
    "Now that you have completed the assignment, follow the steps below to submit your aissgnment:\n",
    "1. Click __Runtime__  > __Run all__ to generate the output for all cells in the notebook. \n",
    "2. Save the notebook (__File__  > __Save__) with the output from all the cells in the notebook by click __File__ > __Download .ipynb__.\n",
    "3. **Keep the output cells** , and answers to the question in the Text cell. \n",
    "4. Put the .ipynb file under your hidden directory on the Zoo server `~/hidden/<YOUR_PIN>/Homework2/`.\n",
    "5. As a final step, run a script that will set up the permissions to your homework files, so we can access and run your code to grade it. Make sure the command be;pw runs without errors, and do not make any changes or run the code again. If you do run the code again or make any changes, you need to run the permissions script again. Submissions without the correct permissions may incur some grading penalty.\n",
    "`/home/classes/cs477/bash_files/hw2_set_permissions.sh <YOUR_PIN>`\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of PartC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2739ec6f25cc4fb19358a7eb5718a5fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27b96391280d493baed65b2f024b8664",
       "IPY_MODEL_352fe954bf8c4b60ac85327f1a3190ae"
      ],
      "layout": "IPY_MODEL_4853c512aad14ee29db649dab221978e"
     }
    },
    "27b96391280d493baed65b2f024b8664": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbf08395a6d44b52a6a30fd76a467f55",
      "max": 361,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_931ea5d0c0fd40d4b28f4cb1266bf7ec",
      "value": 361
     }
    },
    "28bd0cc7fcd248bc9172d27317dda90f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28f46bb8b6704b5e8c8b23775d729a22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1f51751d18c4984aae9aee51f0e7971",
       "IPY_MODEL_f6fc95f39c72412b97e62023f1dab310"
      ],
      "layout": "IPY_MODEL_60f6d057afdb4998a755789f0f29b0c1"
     }
    },
    "352fe954bf8c4b60ac85327f1a3190ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28bd0cc7fcd248bc9172d27317dda90f",
      "placeholder": "​",
      "style": "IPY_MODEL_4a310ab0da8b496e9c9b385268500a74",
      "value": "100% 361/361 [00:00&lt;00:00, 14.0kB/s]"
     }
    },
    "37a6ecf6bf224f998bb7e326a35b7daa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4853c512aad14ee29db649dab221978e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a310ab0da8b496e9c9b385268500a74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4aa6fbbac08a474d92db033d592b84b5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5de8dafa39d34efabe7a6d6296a1dc2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60f6d057afdb4998a755789f0f29b0c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89b37bc329d742289048bfd093cd619b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c40014b839940bc86adb70c64b4a63f",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd3a493815d84118952b5f86ed7b44d0",
      "value": 440473133
     }
    },
    "8c40014b839940bc86adb70c64b4a63f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "931ea5d0c0fd40d4b28f4cb1266bf7ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9460143f748e4b93882bcd0131927466": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3da39ce6cd9494287b1cc0ce2b6e44a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_89b37bc329d742289048bfd093cd619b",
       "IPY_MODEL_c88d21196806475c9937d5474cbc06a0"
      ],
      "layout": "IPY_MODEL_4aa6fbbac08a474d92db033d592b84b5"
     }
    },
    "bcd67acc3c534a358eb9a1e62a889337": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c88d21196806475c9937d5474cbc06a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37a6ecf6bf224f998bb7e326a35b7daa",
      "placeholder": "​",
      "style": "IPY_MODEL_5de8dafa39d34efabe7a6d6296a1dc2a",
      "value": "100% 440M/440M [00:07&lt;00:00, 60.7MB/s]"
     }
    },
    "cbf08395a6d44b52a6a30fd76a467f55": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9acf84a1a874f7ca580b6504f2642dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd3a493815d84118952b5f86ed7b44d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e4ae8e8234244089b0172b1901288a5e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1f51751d18c4984aae9aee51f0e7971": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4ae8e8234244089b0172b1901288a5e",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bcd67acc3c534a358eb9a1e62a889337",
      "value": 231508
     }
    },
    "f6fc95f39c72412b97e62023f1dab310": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9acf84a1a874f7ca580b6504f2642dc",
      "placeholder": "​",
      "style": "IPY_MODEL_9460143f748e4b93882bcd0131927466",
      "value": "100% 232k/232k [00:00&lt;00:00, 7.38MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
